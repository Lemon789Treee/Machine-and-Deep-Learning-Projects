{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnfnmoBhSeoZ",
        "outputId": "da6de6b6-7699-4dd8-c737-5c5c7294b2a7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "import keras.optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define class labels for the classification task\n",
        "class_labels = [\n",
        "    \"combat\",\n",
        "    \"destroyedbuilding\",\n",
        "    \"empty\",\n",
        "    \"fire\",\n",
        "    \"humanitarianaid\",\n",
        "    \"militaryvehicles\",\n",
        "]\n",
        "\n",
        "# Define the size of the input images\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "# Check if CUDA is available, if not, default to CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)  # Print the device (CUDA if available, otherwise CPU)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GHprMkyTAiB"
      },
      "outputs": [],
      "source": [
        "# Function Name: preprocess_and_display\n",
        "# Input: image_path (str) - the path to the input image file\n",
        "# Output: input_batch (torch.Tensor) - preprocessed image tensor\n",
        "# Logic: This function preprocesses an image using a predefined transformation pipeline\n",
        "#        and displays it using OpenCV if the 'display' flag is set to True.\n",
        "# Example Call: input_batch = preprocess_and_display(\"path_to_image.jpg\")\n",
        "\n",
        "# Define the transformation pipeline for preprocessing images\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(IMG_SIZE),  # Resize the image to IMG_SIZE\n",
        "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "        transforms.Normalize(  # Normalize the image using mean and std\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def preprocess_and_display(image_path):\n",
        "    img = Image.open(image_path)  # Open the image file using PIL\n",
        "    input_tensor = transform(img)  # Apply the predefined transformation pipeline\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check device availability\n",
        "    input_batch = input_batch.to(device)  # Transfer the tensor to the appropriate device\n",
        "\n",
        "    if display:\n",
        "        numpy_img = input_tensor.permute(1, 2, 0).numpy()  # Convert tensor to NumPy array\n",
        "        numpy_img = cv.cvtColor(numpy_img, cv.COLOR_BGR2RGB)  # Convert color space for display\n",
        "        cv.imshow(\"Preprocessed Image\", numpy_img)  # Display the preprocessed image\n",
        "        cv.waitKey(200)  # Wait for a short duration\n",
        "        cv.destroyAllWindows()  # Close the OpenCV windows\n",
        "\n",
        "    return input_batch  # Return the preprocessed image tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uV0FFBBTY7w"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setting the directories for the training , test ,validation datasets and the model itself.\n",
        "\n",
        "train_data_dir = r\"C:\\Users\\moonr\\Desktop\\Bonus model training\\Dataset\\Train_Set\"\n",
        "test_data_dir = r\"C:\\Users\\moonr\\Desktop\\Bonus model training\\Dataset\\Test_Set\"\n",
        "val_dir =  r\"C:\\Users\\moonr\\Desktop\\Bonus model training\\Dataset\\Validation_Set\"\n",
        "model_dir = r\"C:\\Users\\moonr\\Desktop\\Bonus model training\\Model\\modelv3.h5\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTi9Pgs6UAho"
      },
      "outputs": [],
      "source": [
        "# Function Name: create_image_data_generators\n",
        "# Input: None\n",
        "# Output: train_datagen (tf.keras.preprocessing.image.ImageDataGenerator),\n",
        "#         test_datagen (tf.keras.preprocessing.image.ImageDataGenerator)\n",
        "# Logic: This function creates image data generators for training and testing data.\n",
        "#        It applies various data augmentation techniques to the images for better model generalization.\n",
        "# Example Call: train_gen, test_gen = create_image_data_generators()\n",
        "\n",
        "# Define the ImageDataGenerator for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=5,  # Degree range for random rotations\n",
        "    width_shift_range=0.1,  # Fraction of total width for horizontal shift\n",
        "    height_shift_range=0.1,  # Fraction of total height for vertical shift\n",
        "    shear_range=0.02,  # Shear intensity\n",
        "    zoom_range=0.01,  # Range for random zoom\n",
        "    horizontal_flip=1,  # Randomly flip inputs horizontally\n",
        "    brightness_range=(0.1, 1.9),  # Range for adjusting brightness\n",
        "    fill_mode=\"constant\",  # Strategy for filling in newly created pixels\n",
        "    cval=255,  # Value used for filling in newly created pixels\n",
        "    preprocessing_function=preprocess_input,  # Function applied to each input\n",
        ")\n",
        "\n",
        "# Define the ImageDataGenerator for testing data\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=5,  # Degree range for random rotations\n",
        "    width_shift_range=0.1,  # Fraction of total width for horizontal shift\n",
        "    height_shift_range=0.1,  # Fraction of total height for vertical shift\n",
        "    shear_range=0.02,  # Shear intensity\n",
        "    zoom_range=0.01,  # Range for random zoom\n",
        "    horizontal_flip=1,  # Randomly flip inputs horizontally\n",
        "    brightness_range=(0.1, 1.9),  # Range for adjusting brightness\n",
        "    fill_mode=\"constant\",  # Strategy for filling in newly created pixels\n",
        "    cval=255,  # Value used for filling in newly created pixels\n",
        "    preprocessing_function=preprocess_input,  # Function applied to each input\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMSZUn4bUO-i",
        "outputId": "dd321793-ad81-4532-aee4-d2f188f667fd"
      },
      "outputs": [],
      "source": [
        "# Function Name: create_model_and_train\n",
        "# Input: None\n",
        "# Output: None\n",
        "# Logic: This function creates a deep learning model for image classification using\n",
        "#        transfer learning with the ResNet50V2 architecture. It then trains the model\n",
        "#        using the provided training and testing data generators.\n",
        "# Example Call: create_model_and_train()\n",
        "\n",
        "# Define constants\n",
        "NUM_CLASSES = 6  # Number of classes for classification\n",
        "BATCH_SIZE = 32  # Batch size for training\n",
        "EPOCHS = 40  # Number of epochs for training\n",
        "LR = 0.0002  # Learning rate for the optimizer\n",
        "\n",
        "TRAIN_DIR = train_data_dir  # Directory containing training images\n",
        "TEST_DIR = test_data_dir  # Directory containing testing images\n",
        "\n",
        "# Load the pre-trained ResNet50V2 model with weights from ImageNet\n",
        "base_model = ResNet50V2(\n",
        "    weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE + (3,)\n",
        ")\n",
        "\n",
        "# Freeze all layers in the base model to prevent their weights from being updated during training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a Sequential model to append layers for transfer learning\n",
        "model = Sequential()\n",
        "model.add(base_model)  # Add the pre-trained base model\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())  # Global average pooling layer\n",
        "model.add(Dropout(0.5))  # Add dropout after the pooling layer\n",
        "model.add(\n",
        "    Dense(NUM_CLASSES, activation=\"softmax\", kernel_regularizer=l2(0.01))\n",
        ")  # Add output layer with softmax activation for classification\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "optim = keras.optimizers.Adam(learning_rate=LR)\n",
        "model.compile(optimizer=optim, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Create data generators for training and testing data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Define model training callbacks\n",
        "metric = \"accuracy\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=model_dir,\n",
        "    monitor=metric,\n",
        "    verbose=2,\n",
        "    save_best_only=True,\n",
        "    mode=\"max\",\n",
        ")\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=4)\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# Start model training and record the time taken for training\n",
        "start = datetime.now()\n",
        "model_history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0skNPmrUu_u"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting the values \n",
        "\n",
        "plt.plot(model_history.history[\"accuracy\"])\n",
        "plt.plot(model_history.history[\"val_accuracy\"])\n",
        "plt.title(\"CNN Model accuracy values\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU--C5GGUyg-"
      },
      "outputs": [],
      "source": [
        "# Function Name: validate_model\n",
        "# Input: model_dir (str) - directory containing the saved trained model,\n",
        "#        val_dir (str) - directory containing validation data,\n",
        "#        IMG_SIZE (tuple) - size of input images for validation\n",
        "# Output: None\n",
        "# Logic: This function validates the trained model using validation data.\n",
        "#        It loads the model, iterates over the validation dataset, predicts\n",
        "#        the classes of images, and calculates the classification accuracy\n",
        "#        for each class. Finally, it prints the classification results.\n",
        "# Example Call: validate_model(model_dir, val_dir, IMG_SIZE)\n",
        "\n",
        "# Load the trained model from the saved directory\n",
        "loaded_model = load_model(model_dir)\n",
        "\n",
        "# Print the summary of the loaded model\n",
        "print(loaded_model.summary())\n",
        "\n",
        "# Define the class labels for classification\n",
        "class_labels = [\n",
        "    \"combat\",\n",
        "    \"destroyedbuilding\",\n",
        "    \"empty\",\n",
        "    \"fire\",\n",
        "    \"humanitarianaid\",\n",
        "    \"militaryvehicles\",\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store classification results\n",
        "result_list = []\n",
        "\n",
        "# Iterate over the directories containing validation data\n",
        "for classes in os.listdir(val_dir):\n",
        "    total_images = 0  # Initialize total number of images\n",
        "    correct = 0  # Initialize number of correctly classified images\n",
        "\n",
        "    # Iterate over images in each class directory\n",
        "    for images in os.listdir(val_dir + \"/\" + classes):\n",
        "        img_path = val_dir + \"/\" + classes + \"/\" + images  # Get the image path\n",
        "        img = image.load_img(img_path, target_size=IMG_SIZE)  # Load the image\n",
        "        img_array = image.img_to_array(img)  # Convert image to array\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions\n",
        "        img_array = preprocess_input(img_array)  # Preprocess the input image\n",
        "        probabilities = loaded_model.predict(img_array)  # Get class probabilities\n",
        "        predicted_class_index = np.argmax(probabilities)  # Get the predicted class index\n",
        "        pred = class_labels[predicted_class_index]  # Get the predicted class label\n",
        "\n",
        "        # Check if the prediction matches the true class label\n",
        "        if classes == pred:\n",
        "            correct += 1  # Increment correct count\n",
        "        total_images += 1  # Increment total images count\n",
        "\n",
        "    # Append the result for the current class to the result_list\n",
        "    result_list.append(\n",
        "        str(\n",
        "            str(correct)\n",
        "            + \"/\"\n",
        "            + str(total_images)\n",
        "            + \"    \"\n",
        "            + str(round((correct / total_images) * 100))\n",
        "            + \"%   --> \"\n",
        "            + classes\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Print the classification results for each class\n",
        "for i in result_list:\n",
        "    print(i)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
